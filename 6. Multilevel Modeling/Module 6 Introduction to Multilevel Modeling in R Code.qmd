---
title: "Module 6 Multilevel Modeling (Introduction)"
author: "Eric R. Schuler, Ph.D."
date: "`r Sys.Date()`"
format: gfm

---

This module will cover the basics of multilevel modeling in R when
working with nested data. Specifically, we will cover:

1.  How to restructure data
2.  Assess the degree of nestedness
3.  Running some basic two-level multilevel models

The code for this workshop has been adapted from the *LME4 Tutorial:
Popularity Data* by Laurent Smeets and Rens van de Shoot (see:
https://www.rensvandeschoot.com/tutorials/lme4/)

Set Working Directory

```{r}
setwd("C:/Users/eschuler/Desktop/r short course/")
```

We will now check to see if the packages we need are already installed
(if any are missing they will be added)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

list.of.packages <- c("tidyverse","backports","boot","broom","equatiomatic","ggplot2",
                       "lme4","lattice","lmerTest","ICC","MuMIn","plyr","psych", 
                      "texPreview","performance", "arm","broom.mixed", "flextable",
                      "modelsummary","qqplotr")
#If you do not already have the package installed, the package is retained
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
#Install packages that are not previously installed
if(length(new.packages)) install.packages(new.packages,repos = "http://cran.us.r-project.org")

library(tidyverse)       #data cleaning and modeling functions
library(backports)       #calling older R functions
library(boot)            #for bootstrapping
library(broom)           #functions for model summaries
library(ggplot2)         #visualizations
library(lattice)         #Visualizations
library(lme4)            #linear mixed effects models, does not calculate p-values
library(lmerTest)        #Obtain p-values for coefficients
library(ICC)             #Intraclass correlation coefficient package
library(MuMIn)           #Extract effect sizes and coefficients
library(psych)           #descriptive statistics
library(plyr)            #functions for data cleaning
library(broom.mixed)     #for printing out p-values in tables
library(equatiomatic)    #extract the model implied equation
library(texPreview)      #view the equations before knitting the rmarkdown file
library(arm)             #additional functions for multilevel modeling
library(modelsummary)    #Functions for creating model tables
```

# What is multilevel modeling?

Multilevel modeling (MLM) is a analytical method to run regressions with
data that has a nested structure to it. For example students nested
within classrooms or daily responses nested within participants. By not
accounting for the nested data structure, it is possible that there may
be violations to the independence of observations assumption that
regression has. Sometimes the data can be nested but that nestedness
does not carry heavy influence, this is something that needs to be
assessed prior to running the model. Multilevel regression models are
sometimes called random coefficient models, variance component models,
hierarchical linear models, or mixed effects models (Hox, Moerbeekk, &
van de Schoot, 2010 p.11). All these models assume a single outcome that
is measured as the lowest level and independent variables all existing
levels (level 1 and level 2 for a two-level MLM). It is important to
note that these different models are not exactly the same though. For
this workshop we are going to be using a basic two-level regression
model.

For this tutorial we will be using data from the book Multilevel
Analysis: Techniques and Applications (Second Edition) by Joop J. Hox.
The data can be located on GitHub as an SPSS .sav datafile (we will read
it directly in to R):
https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/blob/master/chapter%202/popularity/SPSS/popular2.sav

*Please note that these data sets are for educational/teaching purposes
only.*

Our data consists of students nested within classrooms and have
variables at the student level and classroom (teacher) level. There are
100 classrooms and approximately 20 students per classroom (the average
class size is 20 students, this is information later).

Here is a description of the dataset from Hox (2010, Appendix A, p.
352):

*"The popularity data in popular2.csv are simulated data for 2000 pupils
in 100 schools. The purpose is to offer a very simple example for
multilevel regression analysis. The main outcome variable is the pupil
popularity, a popularity rating on a scale of 1--10 derived by a
sociometric procedure. Typically, a sociometric procedure asks all
pupils in a class to rate all the other pupils, and then assigns the
average received popularity rating to each pupil. Because of the
sociometric procedure, group effects as apparent from higher-level
variance components are rather strong. There is a second outcome
variable: pupil popularity as rated by their teacher, on a scale from 1
to 10. The explanatory variables are pupil sex (boy = 0, girl = 1),
pupil extraversion (10-point scale), and teacher experience in
years....The popularity data have been generated to be a 'nice'
wellbehaved data set: the sample sizes at both levels are sufficient,
the residuals have a normal distribution, and the multilevel effects are
strong."*

Our outcomes is popularity, measured at the student level.

We have a level 1 independent variable of student sex (dummy coded) and
student extraversion (self-reported ranging from 1 to 10, so we will
treat it as continuous). We also have a level 2 independent variable of
teacher experience (ranging from 2 to 25 years).

Our multilevel equation is going to look like:

$$y_{ij} = \beta_{0j} + \beta_{1j}x_{ij} + \beta_{2j}x_{ij} +  e_{it}$$

The notation $i$ represents individual students (i = 1, ..., 2000), $j$
represents the classes (j = 1, ...,100).

\[In this equation, our outcome variable of popularity ($y_{it}$) is a
function of the person specific intercept,$\beta_{0i}$ , a
class-specific slope ($\beta_{1i}$), which will indicate the
within-class association of popularity, and the residual error,
$e_{it}$.\]

$$\beta_{0i} = \gamma_{00} + \gamma_{01}z_{i} + u_{0i}$$

\[Where the $\gamma_{00}$ is fixed effect of the average class'
intercept, $\gamma_{01}$ is used to represent the class differences in
the class-specific intercepts related to the between-class differences
in the variable $z_{1i}$. $u_{0i}$ is a random effect and residual of
unexplained differences in the intercepts.\]

$$\beta_{1i} = \gamma_{10} + \gamma_{11}z_{i} + u_{1i}$$ Where the
$\gamma_{00}$ is fixed effect of the average class' slope, $\gamma_{01}$
is used to represent the class differences in the class-specific slopes
related to the between-class differences in the variable $z_{1i}$.
$u_{1i}$ is a random effect and residual of unexplained differences in
the slopes.

When we rearrange the equations into one complex equation it will look
like:

$$Y_{ij} = \gamma_{00} + \gamma_{10}X_{1ij} + \gamma_{20}X_{2ij} + \gamma_{01}Z_{1j} + \\ \gamma_{11}X_{1ij}Z_j + \gamma_{21}X_{2ij}Z_j + u_{1j}X_{1ij} + u_{2j}X_{2ij} + u_{0j} + e_{ij}$$

With variable labels the equation is:

$$popularity_{ij} = \gamma_{00} + \gamma_{10}sex_{ij} + \gamma_{20}extraversion_{ij} + \gamma_{01}experience_{j} + \\ \gamma_{11}gender_{1ij} *experience_j + \gamma_{21}extraversion_{ij}*experience_j + \\ u_{1j}gender_{ij} + u_{2j}extraversion_{ij} + u_{0j} + e_{ij}$$
\# Load the dataset

We will now pull the data set directly from GitHub and import the SPSS
file into R.

```{r}
popular_data <- haven::read_sav(file ="https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/blob/master/chapter%202/popularity/SPSS/popular2.sav?raw=true")
```

There are some variables that will not be used in the dataset, so we
will subset them to only the variables of interest

```{r}
popular_data <- popular_data[,c("pupil","class",
                                "extrav","sex",
                                "texp","popular")]
```

Let's look at the descriptive statistics of the dataset

```{r}
psych::describe(popular_data)
```

We can also look at descriptives by classroom

```{r}
means <- psych::describeBy(popular_data$popular, group = as.factor(popular_data$class), mat = TRUE)
means <- means[,c("group1","n","mean","sd","median", "skew","kurtosis","se")]
rownames(means) <-NULL
htmlTable::htmlTable(format(means, digits = 2)) 
```

Now we will look at the histogram of popularity scores (ignoring the
multilevel data structure)

```{r}
ggplot(data=popular_data, aes(x = popular)) +
    geom_histogram(fill = "light blue", color = "black", bins = 20)+
    labs(x = "Popularity Schores (Higher Scores = More Popular)")
```

We can also look at the relationship with extraversion and popularity
(ignoring the multilevel data structure)

```{r}
ggplot(data  = popular_data,
       aes(x = extrav,
           y = popular))+
  geom_point(size = 1.2,
             alpha = .8,
             position = "jitter")+# to add some random noise for plotting purposes
  theme_minimal()+
  labs(title = "Popularity vs. Extraversion",
   subtitle ="Ignoring the multilevel data structure")
```

We can now shade the data points for each classroom

```{r}
ggplot(data    = popular_data,
       aes(x   = extrav,
           y   = popular,
           col = class))+ 
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(100))+
  labs(title    = "Popularity vs. Extraversion")

```

If we wanted to draw a regression line for each of the 100 classrooms in
the data, it would look like this:

```{r}
ggplot(data      = popular_data,
       aes(x     = extrav,
           y     = popular,
           col   = class,
           group = class))+ 
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ 
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(100))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ 
  labs(title    = "Popularity vs. Extraversion")
```

We can also isolate the simple regression lines by taking a subset of
the classrooms

```{r}
ggplot(data=popular_data[which(popular_data$class <=12),],
       aes(x = extrav, y = popular)) +
  geom_point()+
  stat_smooth(method = "lm", fullrange = TRUE)+
  xlab("Extraversion")+
  ylab("Popularity")+
  facet_wrap(~class)+
  theme(axis.title = element_text(size=16),
        axis.text = element_text(size = 14),
        strip.text = element_text(size = 14))
```

# A note on centering.

In our example we are not going to center the level 1 variables.
Centering is important to note as it will change the interpretation of
the results and it really depends on what the multilevel research
question is (Peugh, 2010, p. 87).

There are two primary ways to center multilevel data. The first is
cluster centering, which means that the individual response of a
variable is centered based on the mean of each cluster. There is also
grand mean centering, which is centering based on the mean of the entire
sample.

Cluster (group-mean) centering is used when the research question is
focusing on the relationship of the independent variables on the
dependent variable at the level 1 or if the level 1 independent variable
interactions with another predictor. This allows for an unbiased
estimate (Peugh, 2010, p. 91). Specifically, the new score captures the
student's score in relation to the cluster/classroom (McCoach, 2010).

Grand mean centering is used when the research question is focusing on
the influence of the independent variable at the level 2 or "grand-mean
centering level-1 predictors adjusts response variable means for the
influence of the predictor in a manner similar to analysis of covariance
(ANCOVA), but it also results in level-1 slope estimates that are an
uninterpretable mix of the level-1 and level-2 relationships (Peugh,
2010, p. 91-92). With grand mean centering the new score captures the
student's score in relation to the entire sample (McCoach, 2010).

# Assessing the degree of nestedness (or do I really need to use MLM?)

Prior to running any meaningful MLM model with independent variables it
is important to assess the degree of nestedness to determine if MLM is
needed. If it is not needed an ordinary least squares regression could
suffice. We will start with the intercept only model, which allows us to
extract the between classroom variability and total variability in
popularity.

Model 0: Intercept-Only Model

In the code below, the '1' indicates the intercept, since we are running
an intercept only model, no other independent variables are included.
The (1\|class) signifies that there are random effects, there is a slope
and the variables to the right of $|$ is the grouping, specifically
students nested within classrooms. This model simply is the outcome
variable of $popular$ statistically predicted by an intercept and a
random error term for the intercept.

```{r}
model0 <- lmer(formula = popular ~ 1 + (1|class), 
                         data = popular_data,
                         na.action = na.exclude)

summary(model0)
deviance(model0,REML=FALSE)
```

We can also look at the intercepts for each classroom (just the first 10
using the head() function)

```{r}
head(coef(model0))
```

Extract the random effects

```{r}
VarCorr(model0)
```

The intraclass correlation coefficient (ICC) is a way to calculate the
degree of nestedness within the data. Specifically it is the proportion
of variation in the outcome that occurs between the groups versus the
total variation present (Finch, Bolin, and Kelley, 2014, p. 24). The ICC
ranges from 0 (no variance among clusters) to 1 (variance among clusters
but no variance within-cluster). The $ICC$ is calculated by taking the
proportion of taking the variance across clusters ($\tau_{00}$) divided
by the variance across clusters plus the variation within clusters
($\tau_{00} + \sigma^2$)

$$ICC = \tau_{00} / (\tau_{00} + \sigma^2)$$

It is important to note that there are no set benchmarks or thresholds
of the ICC to determine with using MLM is warranted. There have been
numerous simulations on the design effect, which provides a means to
empirically assess if the use of MLM is warranted. The design effect is
a means to quantify the effects of the violation of independence on the
standard error estimates, which is an estimate of the multiplier that
needs to be applied to the standard errors to correct for the negative
bias from having nested data (Peugh, 2010, p. 91).

$$Design Effect = 1 + (n_c -1)*ICC$$

Where $n_c$ is the average number of responses within the cluster. If
the design effect estimate is greater than 2.0, then MLM should be
utilized (see: Muthén, 1991, 1994; Muthén & Satorra, 1989, 1995)

We will now begin to calculate the ICC by extracting the variances and
store as a data frame

```{r}
random_effects <- as.data.frame(VarCorr(model0))

random_effects
```

Compute the ICC

```{r}
icc_between <- random_effects[1,4]/(random_effects[1,4]+random_effects[2,4])

icc_between
```

Alternatively we can use the performance package

```{r}
performance::icc(model0)
```

Calculate the design effect

```{r}
icc_m2 <- Hmisc::deff(popular_data$popular,popular_data$class)
icc_m2
```

Difference is in the rounding.

```{r}
de <- 1 + ((20-1)*icc_between)
de
```

```{r}
de2 <- 1 + (((icc_m2[1]/icc_m2[2])-1)*icc_m2[3])
de2
```

Based on the design effect of `r round(icc_m2[4],2)` being larger than
2, running an MLM model is warranted.

# Model building

Hox (2010) takes a modeling building approach where independent
variables are added sequentially in blocks within the model and the
deviance score is assessed. Deviance is produced by the maximum
likelihood procedure and it indicated how well the model fits the data.
Deviance is a log0likelihood test of the current model minus the
saturated model. The lower the deviance the better the model fits. So we
are looking to have an reduction in deviance as we include more
meaningful independent variables. If this approach is utilized, it is
good practice to report each of the models that were run in the analyses
and what criteria was used to determine which model was retained as a
final model for interpretation.

Model 1: with level 2 independent variables (extraversion and sex)

Before running the model, let's visualize the relationship between
extraversion and popularity with a regression line for each sex. Note
that this is ignoring the multilevel data structure.

```{r}
ggplot(data = popular_data, 
       aes(x   = extrav,
           y   = popular, 
           col = as.factor(sex)))+
  geom_point(size     = 1, 
             alpha    = .7, 
             position = "jitter")+
  geom_smooth(method   = lm,
              se       = T, 
              size     = 1.5, 
              linetype = 1, 
              alpha    = .7)+
  theme_minimal()+
  labs(title    = "Linear Relationship Between Popularity and Extraversion for the 2 Genders")+
  scale_color_manual(name   =" Gender",
                     labels = c("Boys", "Girls"),
                     values = c("Green", "Red"))

```

```{r}
model1 <- lmer(formula = popular ~ 1 + sex + 
                 extrav + (1|class), 
                         data = popular_data,
                         na.action = na.exclude)

summary(model1)
deviance(model1, REML=FALSE)
```

We can note that the deviance in model 1
(`r round(deviance(model1, REML=FALSE),2)`) is less than the intercept
only model (`r round(deviance(model0, REML=FALSE),2)`), meaning that the
model 1 does a better job as deviance is a measure of model badness.
This is the approach used in Gelman and Hill (2007, p. 526). For nested
models, the deviance scores can be used to compare models (i.e. null
model versus a model with independent variables) and the deviance scores
can be compared using a chi-squared difference test (McCoach, 2010, p.
135). For example:

```{r}
anova(model0, model1)
```

After looking at the deviance, we can then look at the coefficients by
classroom (just the first 10 using the head() function)

```{r}
head(coef (model1))
```

We can also examine the fixed effects separately.

```{r}
fixef (model1)
```

And the random effects of the model (will be just intercepts since that
is our only random effect). We will just print the first 10 using the
head() function

```{r}
head(ranef (model1))
```

Then we can also look at the standard errors of the coefficients

```{r}
se.fixef (model1) # for the fixed effects
head(se.ranef (model1)) # for the intercept of each classroom, just the first 10
```

Model 2: Including a second level independent variable (teacher
experience)

```{r}
model2 <- lmer(formula = popular ~ 1 + sex + 
                 extrav + texp + (1|class), 
                         data = popular_data,
                         na.action = na.exclude)

summary(model2)
deviance(model2, REML=FALSE)
```

Now we are going to add random slopes for the variables. This is done by
adding variables to the left of the $|$.

Model 3: Random slopes

```{r}
model3 <- lmer(formula = popular ~ 1 + sex + 
                 extrav + texp + 
                 (1 + sex + extrav | class),
               data    = popular_data)

summary(model3)
deviance(model3, REML=FALSE)
```

As the random slope for sex was not statistically significant we can
remove it as part of the model trimming (if we were to write up the
results we would have a table with each model reported and discuss the
decision points for transparency)

Model 4: Omit the random slope for sex

```{r}
model4 <- lmer(formula = popular ~ 1 + sex + 
                 extrav + texp + 
                 (1 + extrav | class),
               data    = popular_data)

summary(model4)
deviance(model4, REML=FALSE)
```

We can also examine a crosslevel interaction between teacher's
experience and extraversion. Specifically are the differences in the
relationship between extraversion and popularity explained by teacher's
experience? This would mean that teacher's experience is a moderator in
the relationship. To be able to create the interaction term between
extraversion and teacher's experience we would write extrav:texp.

```{r}
model5<-lmer(formula = popular ~ 1 + sex + extrav + texp+ extrav:texp + (1 + extrav | class), 
             data    = popular_data)
summary(model5)
deviance(model5, REML=FALSE)
```

Based on the deviance score of
`r round(deviance(model5, REML=FALSE),2)`, we would retain and interpret
this final model.

We can also run the chi-squared test:

```{r}
anova(model4, model5)
```

Obtain coefficients for intercept/slope for each classroom

```{r}
coef(model5)$class
coef_1<-coef(model5)$class
```

extract fixed effects

```{r}
coef(summary(model5))[,"Estimate"]
```

extract random effects

```{r}
random_e <-ranef(model5)$class
```

we will now bind this into a table

```{r}
names(random_e) <- c("Inter_RE", "Extra_RE")
coef_table<-cbind(coef_1, random_e)
coef_table
```

Let's visualize the final model we will be retaining and interpreting

```{r}
ggplot(data = popular_data,
       aes(x = extrav, 
           y = popular, 
           col = as.factor(texp)))+
  viridis::scale_color_viridis(discrete = TRUE)+
  geom_point(size     = .7,
             alpha    = .8, 
             position = "jitter")+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = 2,
              alpha  = .8)+
  theme_minimal()+
  labs(title    = "Linear Relationship for Different Years of Teacher Experience as Observed", 
       subtitle = "The linear relationship between the two is not the same for all classes", 
       col      = "Years of\nTeacher\nExperience")
```

We can also look at the random effects visually (code from:
https://stackoverflow.com/questions/13847936/in-r-plotting-random-effects-from-lmer-lme4-package-using-qqmath-or-dotplot)

We will add the function to our workspace *Note, re = object of class
ranef.mer*

```{r}
ggCaterpillar <- function(re, QQ=TRUE, likeDotplot=TRUE) {
  require(ggplot2)
  f <- function(x) {
    pv   <- attr(x, "postVar")
    cols <- 1:(dim(pv)[1])
    se   <- unlist(lapply(cols, function(i) sqrt(pv[i, i, ])))
    ord  <- unlist(lapply(x, order)) + rep((0:(ncol(x) - 1)) * nrow(x), each=nrow(x))
    pDf  <- data.frame(y=unlist(x)[ord],
                       ci=1.96*se[ord],
                       nQQ=rep(qnorm(ppoints(nrow(x))), ncol(x)),
                       ID=factor(rep(rownames(x), ncol(x))[ord], levels=rownames(x)[ord]),
                       ind=gl(ncol(x), nrow(x), labels=names(x)))
    
    if(QQ) {  ## normal QQ-plot
      p <- ggplot(pDf, aes(nQQ, y))
      p <- p + facet_wrap(~ ind, scales="free")
      p <- p + xlab("Standard normal quantiles") + ylab("Random effect quantiles")
    } else {  ## caterpillar dotplot
      p <- ggplot(pDf, aes(ID, y)) + coord_flip()
      if(likeDotplot) {  ## imitate dotplot() -> same scales for random effects
        p <- p + facet_wrap(~ ind)
      } else {           ## different scales for random effects
        p <- p + facet_grid(ind ~ ., scales="free_y")
      }
      p <- p + xlab("Levels") + ylab("Random effects")
    }
    
    p <- p + theme(legend.position="none")
    p <- p + geom_hline(yintercept=0)
    p <- p + geom_errorbar(aes(ymin=y-ci, ymax=y+ci), width=0, colour="black")
    p <- p + geom_point(aes(size=1.2), colour="blue") 
    return(p)
  }
  
  lapply(re, f)
}
```

Once the function is in the workspace, we will run it with model 5

```{r}
ggCaterpillar(ranef(model5, condVar=TRUE))  ## using ggplot2
```

Similar visual but with the lattice package

```{r}
lattice::qqmath(ranef(model5, condVar=TRUE)) 
```

# Effect size calculation in MLM

There are two ways to calculate effect sizes for mlm. The first are
analogues for $R^2$ that are variance accounted of the dependent
variable for each level (done separately). The second is a proportional
reduction in variance, which is used to estimate the variance explained
for any variance component in the model compared to a baseline model
(McCoach, 2010, p. 136). As it is a comparison from one model to
another, the statistic cannot be interpreted as an absolute variance
accounted for of the dependent variable (McCoach, 2010, p. 137). It is
more common to see the proportional reduction in variance than the $R^2$
analogue for level-1 and level-2. Both are presented below though
starting with the $R^2$ analogues. We will start with the analogue of
$R^2$ and then return to proportional reduction.

Level 1 variance accounted for can be calculated as:

$$R^2_{level1} = 1 - (\sigma^2_{model1} + \tau^2_{model1})/(\sigma^2_{model0} + \tau^2_{model0})$$

Level 2 variance accounted for can be calculated as (where $n_c$ is the
average number of responses within the clusters, in our sample it is 20:

$$R^2_{level2} = 1 - (\sigma^2_{model1} / n_c + \tau^2_{model1})/(\sigma^2_{model0} / n_c +  \tau^2_{model0})$$

First we will extract the variance covariance information from the
retained model (model 5)

```{r}
random_effects_m1 <- as.data.frame(VarCorr(model5))
random_effects_m1
```

As a refresher, here are the information for the intercept-only model
and our final model, which we saved as an object in R previously.

```{r}
random_effects
```

Now we can plug that into our $R^2$ analogue equations.

For level-1 $R^2$

```{r}
rsquared_lvl1 <- 1-((random_effects_m1[4,4] + random_effects_m1[1,4])/(random_effects[2,4] + random_effects_m1[1,4]))
round(rsquared_lvl1,2) 
```

For level-2 $R^2$

```{r}
rsquared_lvl2 <- 1-(((random_effects_m1[4,4]/20) + random_effects_m1[1,4])/((random_effects[2,4]/20) + random_effects_m1[1,4]))
round(rsquared_lvl2,2)
```

Based on the equation above, our $R^2_{level1}$ for our final model was
`r print(round(rsquared_lvl1,2))`, while the level-2 variance accounted
for was `r print(round(rsquared_lvl2,2))`.

It is important to note that these are analogues of $R^2$ and these are
for accounting for variance explained at level-1 and level-2 separately
(McCoach, 2010).

Another common statistic to estimate variance accounted for is the
proportional reduction in variance statistics, which can be calculated
for any variance component in the model (McCoach, 2010, p. 136). This
can be calculated at both the level-1 and level-2 variances.

$$ (\sigma^2_{baseline} - \sigma^2_{f})/ \sigma^2_{baseline}$$ Where
$\sigma^2_f$ is the estimated level-1 variance for the fitted model.

In our example, let's calculate the proportional variance reduction for
the residual (ERIC = IS THIS RIGHT??)

```{r}
pvr_residual <- (random_effects[2,4] - random_effects_m1[4,4]) / random_effects[2,4]
pvr_residual
```

For level-2, the variance components are represented by $\tau_{bb}$ and
can be estimated for each of the intercepts ($\beta_{0j}$) and each
slope that that is allowed to vary randomly across the groups
($\beta_{1j}$). McCoach (2010, p. 137) notes that "the proportional
reduction in the variance for a given slope, $\beta_{qj}$, where
$\tau_{qq_b})$ is the estimated variance of slope q in the base model
and $\tau_{qq_f})$ is the estimated variance of slope q in the fitted
model.

$$ (\tau_{qq_b} - \tau_{qq_f})/ \tau_{qq_b}$$

Now let's calculate the proportional variance reduction for the
intercept $\beta_{0j}$:

```{r}
pvr_intercept <- (random_effects[1,4] - random_effects_m1[1,4])/random_effects_m1[1,4]
pvr_intercept
```

It is important to note that the proportion reduction in variance does
not behave like $R^2$ as it compares one model to another rather than
the amount of of variance explained of the dependent variable (McCoach,
2010, p. 137).

# Coefficient Tables

Some fields prefer interpreting the standardized beta weights

```{r}
MuMIn::std.coef(model5,partial = TRUE) 
```

We can also create a coefficient table with the unstandardized
coefficients

```{r}
MuMIn::coefTable(model5)
```

# Some Assumption Checking

It is important to check the residuals of the model to ensure that the
residuals are normally distributed at both levels.

Check for heteroskedasticity

```{r}
plot(fitted(model5), resid(model5, type = "pearson"))# this will create the plot
abline(0,0, col="red")
```

Check the normality of the residuals

```{r}
qqnorm(resid(model5)) 
qqline(resid(model5), col = "red") # add a perfect fit line
```

We will now inspect the normality of the random effects of extraversion
and the intercept for the classrooms

For the intercept:

```{r}
qqnorm(ranef(model5)$class[,1] )
qqline(ranef(model5)$class[,1], col = "red")
```

For extraversion:

```{r}
qqnorm(ranef(model5)$class[,2])
qqline(ranef(model5)$class[,2], col = "red")
```

We can also try another package that automates the assumption checks.

```{r}
performance::check_model(model5)
```

We can also run the assumption checks separately

```{r}
performance::check_collinearity(model5)
performance::check_heteroscedasticity(model5)
performance::check_normality(model5)
performance::check_outliers(model5)
```

# Writing out the equation (implied by them model)

The following code will write out the equations based on the lme4 code
(see:https://github.com/datalorax/equatiomatic &
https://cran.r-project.org/web/packages/equatiomatic/vignettes/lme4-lmer.html)

```{r}
library(texPreview)
library(equatiomatic)
```

We will extract the model fit without p-values (so the function in the
equatiomatic package can read the object)

```{r}
model5_fit_eq <- lme4::lmer(formula = popular ~ 1 + sex + extrav + texp+ extrav:texp + (1 + extrav | class), 
             data    = popular_data)
```

To view the equation it as we go (not in the knitted R markdown file):

```{r}
tex_preview(extract_eq(model5_fit_eq))
```

To write the equation in an R markdown file

```{r}
extract_eq(model5_fit_eq)
```

# Reporting MLM Results

Checklist for reporting Multilevel Models (Excerpt from: McCoach,2010,
p. 124-125)

1.  Model theory and variables included in the model are consistent with
    the purposes of the study and the research questions or study
    hypotheses.
2.  The decision to include/exclude random effects should be justified
    theoretically. The number of random effects to include should be as
    realistic and yet as parsimonious as possible. If random effects are
    eliminated during the model-building process, this decision should
    be justified both empirically and theoretically.
3.  Statistical model is presented, preferably using equations.
    Otherwise, minimally, the statistical model is described in enough
    verbal detail to be replicable by other researchers, and for the
    reader to determine the fixed effects and the random effects at each
    level for each model.
4.  Sample size is specified at each level, and is sufficient for
    conducting the proposed analysis. Sampling strategy and mode(s) of
    data collection are identified and justified. If appropriate,
    weighting methods are described and justified.
5.  Measurement of the outcome/response variable is described and
    justified. Measurement of all explanatory variables is described and
    justified; evidence of reliability and validity is provided.
6.  Scaling and centering of predictor variables are described and
    justified. Coding of all categorical predictors is fully described.
    Special attention must be paid to the centering/coding of all
    lower-level independent variables and to the implications of these
    centering decisions for interpretation of the model results.
7.  Extent of missing data is clearly reported for all variables at all
    levels, and methods for accommodating missing data are described.
    Special attention is paid to the issue of missing data at higher
    levels of analysis, as higher level units with missing data are
    eliminated from the analysis by default. The final analytical sample
    is described.
8.  For longitudinal models, the shape of the growth trajectory is
    described, and the modeling of this trajectory is described and
    justified.
9.  The software or program used to run the models should be identified.
    Parameter estimation strategy (e.g., REML, ML) is identified and
    justified.
10. Assumptions of the model are described and checked. This may include
    discussions of normality, outliers, multicollinearity, homogeneity
    or heterogeneity of variances, and residual diagnostics.
11. The assumed error covariance structure should be described, and any
    plausible alternative error covariance structures should be
    described and tested. This is especially important for longitudinal
    models.
12. Descriptive statistics for variables at each level of the analysis
    should be reported. These should include means, standard deviations,
    and correlations.
13. The intraclass correlation coefficient for the unconditional model
    should be reported and interpreted.
14. Generally, multilevel models are built sequentially, using a series
    of models: an unconditional model, a random coefficients model
    (containing lower-level predictors), and a full model (containing
    predictors at all level of the analysis). This series of models is
    described.
15. The write-up includes a table that presents the results of the
    analysis. These results should include both fixed effect parameter
    estimates and variance components.
16. Model fit issues are addressed. Deviance is reported for any
    estimated models. Additionally, other measures of model fit (e.g.,
    AIC, BIC) are reported for all estimated models. Competing nested
    models are compared using the likelihood ratio/chi-square difference
    test.

Creating the model table

<Figure out how to remove some aspects>

https://vincentarelbundock.github.io/modelsummary/articles/modelsummary.html#gof-omit-map

First we are going to create an object that lists all the models that we
will be reporting in our table

```{r}
models <- list()
models[['Intercept Only']] <- model0
models[['Model 1']] <- model1
models[['Model 2']] <- model2
models[['Model 3']] <- model3
models[['Model 4']] <- model4
models[['Model 5']] <- model5
```

Next we can use the msummary() to create an html table and have stars to
denote statistical significance. *Please note that the REMLcrit row is
actually our deviance.*

<ERIC FIGURE OUT WHAT CAN BE REMOVED FROM THE TABLE>

```{r}
msummary(models, stars = c('*' = .050, '**' = .010, '***' = .001), output = 'html')
```

We can also write this table as a word document

```{r}
msummary(models, stars = c('*' = .050, '**' = .010, '***' = .001), output = 'mlm_table.docx')
```

Note some of the $NA$ next to some of the variance components and empty
() for the se. We would want to remove those in the document, it is a
function of requesting the asterisks to denote statistical significance.
Additionally, we would want to change REMLcritical to Deviance and also
reformat the p-values in the notes section.

# Citations:

-   Gelman, A., & Hill, J. (2006). Data analysis using regression and
    multilevel/hierarchical models. Cambridge university press.
-   Finch, W. H., Bolin, J. E., & Kelley, K. (2019). Multilevel modeling
    using R. Crc Press.
-   Hox, J. J., Moerbeek, M., & van de Schoot, R. (2010). Multilevel
    Analysis: Techniques and Applications. Routledge.
-   Hox, J. J., Moerbeek, M., & Van de Schoot, R. (2017). Multilevel
    analysis: Techniques and Applications. Routledge.
-   McCoach, D. B. (2010). Hierarchical linear modeling. The reviewer's
    guide to quantitative methods in the social sciences, 123-140.
-   Muthén, B. O. (1991). Multilevel factor analysis of class and
    student achievement components. Journal of Educational Measurement,
    28(4), 338-354.
-   Muthén, B. O. (1994). Multilevel covariance structure analysis.
    Sociological Methods & Research, 22(3), 376-398.
-   Muthén, B., & Satorra, A. (1989). Multilevel aspects of varying
    parameters in structural models. In Multilevel analysis of
    educational data (pp. 87-99). Academic Press.
-   Muthén, B. O., & Satorra, A. (1995). Complex sample data in
    structural equation modeling. Sociological Methodology, 267-316.
-   Peugh, J. L. (2010). A practical guide to multilevel modeling.
    Journal of School Psychology, 48(1), 85-112.

# Resources:

-   https://psu-psychology.github.io/psy-597-SEM/15_multilevel/multilevel_sem.html
-   https://quantdev.ssri.psu.edu/tutorials/r-bootcamp-introduction-multilevel-model-and-interactions
-   https://rpsychologist.com/r-guide-longitudinal-lme-lmer/
-   https://ase.tufts.edu/gsc/gradresources/guidetomixedmodelsinr/mixed%20model%20guide.html
-   https://benwhalley.github.io/just-enough-r/index.html
-   https://www.rensvandeschoot.com/tutorials/lme4/
-   https://quantdev.ssri.psu.edu/tutorials
-   http://mfviz.com/hierarchical-models/

Highly recommend the LEMMA Online MLM Course (it is FREE) from the
Centre for Multilevel Modeling at the University of Bristol:
http://www.bristol.ac.uk/cmm/learning/online-course/
